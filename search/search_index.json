{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CERN Neutrino Group","text":"<p>This is a collection of guides for members of the CERN Neutrino Group. It contains useful computing information for newcomers and also points them to other resources.</p> <p>It is a brief introduction to computing topics at CERN, as well as, a way of sharing best practices.</p> <p>If you notice incorrect information please fill out an issue.</p>"},{"location":"masterclass/","title":"Neutrino Masterclass","text":"<p>During the summer of 2023 we held a masterclass on a variety of neutrino related topics: </p> <ul> <li>Joachim Kopp - Neutrino Oscillations</li> <li>Filippo Resnati - Detector Technologies for Rare Event Searches</li> <li>Eric Zimmerman - Designing and Understanding Modern Neutrino Beams</li> </ul>"},{"location":"meetings/","title":"Meetings","text":"<p>We have group meetings bi-weekly usually on Thursdays at 11 am. Here is a collection of our previous meetings.</p>"},{"location":"slack/","title":"Slack","text":"<p>We have a Slack, contact one of the group members if you require access. </p>"},{"location":"Computing/Environments/","title":"Environments","text":""},{"location":"Computing/Environments/#using-lcg-views","title":"Using LCG Views","text":"<p>The LCG Releases provide an extensive collection of regularly updated software. The list of available software can be seen here. </p> <p>After selecting an appropriate view we can load by sourcing a <code>setup.sh</code> file from <code>cvmfs</code> (this would be available on any <code>lxplus</code> machine): <pre><code>source /cvmfs/sft.cern.ch/lcg/views/&lt;release&gt;/&lt;platform&gt;/setup.sh\n</code></pre></p>"},{"location":"Computing/Environments/#combining-a-virtual-python-env-with-lgc-views","title":"Combining a Virtual Python Env with LGC Views","text":"<p>If we want to customize the software packages provided by the LCG view, we can create a virtual environment on top of the view, thus only installing extra packages, or upgrading existing ones, without having to build a complete environment from scratch. </p> <p>we begin by sourcing the LCG view as above: <pre><code>source /cvmfs/sft.cern.ch/lcg/views/&lt;release&gt;/&lt;platform&gt;/setup.sh\n</code></pre> Then we can create a virtual environment and activate it </p> <pre><code>python3 -m venv --system-site-packages myenv\nsource myenv/bin/activate   # activate the environment\n</code></pre> <p>Finally, if we need to upgrade a certain package we can use <code>pip</code>:</p> <pre><code>pip install --upgrade tensorflow=newer.version\n</code></pre>"},{"location":"Computing/Environments/#using-conda","title":"Using <code>conda</code>","text":"<p>Warning</p> <p>We highly recommend that you use a virtual environment on top of LCG. However it is possible to set up a complete environment from scratch using conda.</p> <p>To set up a conda environment we suggest that your first increase your AFS quota, by following this guide.</p> <p>If you still require more space. i.e <code>/afs/cern.ch/user/&lt;initial&gt;/&lt;username&gt;</code> is filling up, you can point <code>conda</code> to the work directory <code>/afs/cern.ch/work/&lt;initial&gt;/&lt;username&gt;</code>. To do this we need to edit the <code>~/.condarc</code> file.</p> <pre><code>pkgs_dirs: - /afs/cern.ch/work/&lt;initial&gt;/&lt;username&gt;/public/pkgs\nenvs_dirs:\n  - /afs/cern.ch/work/&lt;initial&gt;/&lt;username&gt;/public/envs\n</code></pre>"},{"location":"Computing/GPUs/","title":"GPUs","text":""},{"location":"Computing/GPUs/#lxplus","title":"LXPLUS","text":"<p>The easiest way to access a GPU is by using the LXPLUS service:</p> <p><pre><code>ssh yourusername@lxplus-gpu.cern.ch\n</code></pre> The GPUs are usually an NVIDIA T4. </p> <p>You also access A100 on nodes with AlmaLinux8:</p> <pre><code>ssh yourusername@lxplus8-gpu.cern.ch\n</code></pre>"},{"location":"Computing/GPUs/#swan","title":"SWAN","text":"<p>You can also access GPUs on the SWAN Service. You will have to create a ticket to be granted access, you will be pointed to the link for this when you try to create a session. </p> <p>Using SWAN you have access to GPUs, using CERN's modified version of jupyter notebooks - you can run code interactively, thus it is very good for prototyping. </p> <p>A detailed view of the software available on SWAN is listed on the LCG Release website.</p>"},{"location":"Computing/GPUs/#kubeflow","title":"Kubeflow","text":"<p>The CERN Kubeflow service is focused on deep learning workflows. It contains notebooks, tools for ML pipelines and hyper-parameter optimization.</p>"},{"location":"Computing/GPUs/#lxbatch","title":"LXBATCH","text":"<p>You can view nodes with GPUs by specifying a constraint to <code>condor_status</code>, for example, to view all nodes with more than 2 GPUs:</p> <pre><code>condor_status -constraint 'GPUs &gt; 2'\n</code></pre> <p>We can also filter by GPU type, however, due to the current migration process, this command is different for A100 GPUs and the rest:</p> <ul> <li> <p>On A100 <pre><code> condor_status -constraint 'regexp(\"A100\", CUDADeviceName)'\n</code></pre></p> </li> <li> <p>On everything else <pre><code> condor_status -constraint 'regexp(\"V100\", GPUs_DeviceName)'\n</code></pre></p> </li> </ul> <p>To increase your priority in the queue you can subscribe to the <code>np-comp</code> group.</p> <p>To require a GPU when submitting a job to the HTCondor LXBATCH cluster, we can specify in our <code>.sub</code> the following requirement: <pre><code>request_GPUs = 1\n</code></pre></p> <p>Info</p> <p>Currently only machines with A100 GPUs will be assigned to your job by default. This is due to an ongoing upgrade of the nodes to AlmaLinux9, thus to run a job using V100 or T4 you must specify:</p> <p><pre><code>requirements = TARGET.OpSysAndVer =?= \"AlmaLinux9\"\n</code></pre> If the job can run on both versions then: <pre><code>requirements = ( TARGET.OpSysAndVer =?= \"AlmaLinux9\" || TARGET.OpSysAndVer =?= \"CentOS7\")\n</code></pre></p>"},{"location":"Computing/LXPLUS/","title":"LXPLUS","text":""},{"location":"Computing/LXPLUS/#accessing-lxplus","title":"Accessing LXPLUS","text":""},{"location":"Computing/LXPLUS/#via-the-terminal","title":"Via the Terminal","text":"<p>On Linux and MacOS systems, you can connect via the terminal by typing:</p> <p><code>ssh yourusername@CERN.CH</code></p> <p>You will then be prompted to enter your password. On Windows systems, we recommend using Windows Subsystem for Linux. After installing you can connect the same way as described above.</p>"},{"location":"Computing/LXPLUS/#with-visual-studio-code","title":"With Visual Studio Code","text":"<p>You may use Visual Studio Code as a way of accessing LXPLUS interactive logon service with the full benefits of using an Integrated Development Environment (IDE). </p> <p>After installing, go to the extensions tab (left sidebar at the bottom) and find the Remote - SSH extension and install it. Then, you can open the command palette <code>(ctrl + shift + p)</code> and go to <code>Remote - SSH: Connect to Host</code>, then <code>+ Add New SSH Host...</code> then you can connect as you would in the terminal.</p>"},{"location":"Computing/LXPLUS/#extensions-for-debugging-and-linting","title":"Extensions for Debugging and Linting","text":"<ul> <li>Officially supported extensions for C++ and Python </li> <li>ROOT macros linting and debugging have a look at this blogpost</li> </ul>"},{"location":"Computing/LXPLUS/#setting-up-passwordless-access","title":"Setting up Passwordless Access","text":""},{"location":"Computing/LXPLUS/#linux-and-macos","title":"Linux and MacOS","text":"<p>We can edit the <code>ssh</code> config located in <code>/home/username/.ssh/config</code>. Insert the following into the file by replacing <code>username</code> with your CERN username and <code>vm</code> with the host that we are trying to connect to (for instance <code>lxplus</code>). This configuration allows us to set up a jump connection using the <code>lxtunnel</code> host if we are not on the CERN network, for example, if we are working remotely.</p> <pre><code>Host vm\n  HostName vm.cern.ch\n\nHost *.cern.ch\n    # your CERN username\n    User username\n    GSSAPITrustDns yes\n    GSSAPIAuthentication yes\n    GSSAPIDelegateCredentials yes\n\nMatch host *.cern.ch,!lxtunnel*.cern.ch,!lxplus*.cern.ch !exec \"hostname -A | grep -q '.cern.ch '\"\n  ProxyJump lxtunnel.cern.ch \n</code></pre> <p>Now using the terminal we can get a Kerberos ticket by the command: </p> <pre><code>kinit username@CERN.CH\n</code></pre> <p>Then you should be able to connect via the terminal or using VSCode without having to enter your password.</p>"},{"location":"Computing/LXPLUS/#windows","title":"Windows","text":"<p>Since there is no official support from the Remote SSH extension to use WSL, by default it uses the Windows ssh client. There is however a hacky way of using WSL to make the <code>ssh</code> connection instead. We need to create a <code>.bat</code> file with the following content. </p> <pre><code>C:\\Windows\\system32\\wsl.exe ssh %*\n</code></pre> <p>To point Remote-SSH extension to use that <code>.bat</code> file, we begin by opening the commmand pallete using <code>ctrl + shift + p</code> and selecting <code>&gt; Remote-SSH: Settings</code>. From there we find the <code>Remote.SSH: Path</code> setting and add the absolute path of the <code>.bat</code> file. </p> <p>To make this work seamlessly, we must make sure the contents of the ssh config files are the same in WSL and the default one in Windows. In Windows that file is usually located in <code>C:\\Users\\username\\.ssh\\config</code> and in WSL, it is usually located in <code>/home/username/.ssh/config</code>. After this, this configuration should let you connect to lxplus or any virtual machines behind the CERN firewall.</p>"},{"location":"Computing/sshtunnel/","title":"Tunnelling to connect behind the CERN Firewall","text":"<p>If you are working from home you may not be able to access certain services that are behind the CERN firewall. A possible solution is to use an <code>SSH tunnel</code>. We can set up a tunnel by: <pre><code>ssh -D 8888 lxtunnel.cern.ch\n</code></pre> Which would set up a tunnel on port <code>8888</code>. It is possible to set up the tunnel system wide, as show in this guide, however we advise using the simpler method of a browser extension such as Proxy SwitchOmega to switch between the proxy quickly. </p>"}]}